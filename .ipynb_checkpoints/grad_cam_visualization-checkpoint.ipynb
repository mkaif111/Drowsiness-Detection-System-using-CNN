{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.keras.backend as k\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np \n",
    "import cv2\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from PIL import Image\n",
    "SIZE = 180"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.compat.v1.disable_eager_execution()\n",
    "def get_heatmap(model,pred_img,last_layer,heatmap_for_index = None):\n",
    "    last_conv_layer = model.get_layer(last_layer)\n",
    "    prediction = pred_img[0]\n",
    "    x = pred_img[1]\n",
    "    class_idx = np.argmax(prediction)\n",
    "    if heatmap_for_index is None:\n",
    "        heatmap_for_index = class_idx\n",
    "    class_output = model.output[:,heatmap_for_index]\n",
    "#     heatmap_model = models.Model([model.inputs], [last_conv_layer.output, model.output])\n",
    "#     with tf.GradientTape() as gtape:\n",
    "#         conv_output, predictions = heatmap_model(x)\n",
    "#         loss = predictions[:, np.argmax(predictions[0])]\n",
    "#         grads = gtape.gradient(loss, conv_output)\n",
    "#         pooled_grads = k.mean(grads, axis=(0, 1, 2))\n",
    "    grads = k.gradients(class_output, last_conv_layer.output)[0]\n",
    "    pooled_grads = k.mean(grads, axis=(0,1,2))\n",
    "    iterate = k.function([model.output],[pooled_grads,last_conv_layer.output[0]])\n",
    "    pooled_grads_value, conv_layer_output_value = iterate([x])\n",
    "    for i in range(pooled_grads.shape[-1]):\n",
    "        conv_layer_output_value[:,:,i] *= pooled_grads_value[i]\n",
    "    heatmap = np.mean(conv_layer_output_value,axis = -1)\n",
    "    heatmap = np.maximum(heatmap,0)\n",
    "    heatmap /= np.max(heatmap)\n",
    "    heatmap = cv2.resize(heatmap,(SIZE,SIZE))\n",
    "    heatmap = np.uint8(255*heatmap)\n",
    "    heatmap = np.repeat(heatmap[:,:,np.newaxis],3, axis = 2)\n",
    "    return heatmap\n",
    "def heatmap(image):\n",
    "    prediction = model.predict(image)[0]\n",
    "    print(prediction)\n",
    "    total_cam = np.zeros((SIZE,SIZE,3),dtype = \"float32\")\n",
    "    total_cam += get_heatmap(model,[prediction,image],\"conv2d_5\",np.argmax(prediction))\n",
    "    total_cam -= get_heatmap(model,[prediction,image],\"conv2d_5\",1-np.argmax(prediction))\n",
    "    total_cam /= np.max(np.abs(total_cam))\n",
    "    total_cam *= 255\n",
    "    total_cam = np.unit8(total_cam)\n",
    "    total_cam = Image.fromarray(total_cam).resize((SIZE,SIZE,3))\n",
    "    return total_cam\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 176, 176, 32)      2432      \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 174, 174, 32)      9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 87, 87, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 85, 85, 64)        18496     \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 83, 83, 64)        36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 41, 41, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 39, 39, 128)       73856     \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 37, 37, 128)       147584    \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d (Gl (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 2)                 258       \n",
      "=================================================================\n",
      "Total params: 288,802\n",
      "Trainable params: 288,802\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = load_model(\"chest_xray_classifier_1.h5\")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "NORMAL = \"data/chest_xray/train/NORMAL\"\n",
    "PNEUMONIA = \"data/chest_xray/train/PNEUMONIA\"\n",
    "\n",
    "NORMAL_img = os.listdir(NORMAL)\n",
    "PNEUMONIA_img = os.listdir(PNEUMONIA)\n",
    "\n",
    "img_file = os.path.join(PNEUMONIA, PNEUMONIA_img[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.06868412 0.9313159 ]\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "You must feed a value for placeholder tensor 'conv2d_input_2' with dtype float and shape [?,180,180,3]\n\t [[{{node conv2d_input_2}}]]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-d4eaac2a1809>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;31m# img_tensor = preprocess_input(img_tensor)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[0mheat_img\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mheatmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-9-a3935247df30>\u001b[0m in \u001b[0;36mheatmap\u001b[1;34m(image)\u001b[0m\n\u001b[0;32m     31\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprediction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m     \u001b[0mtotal_cam\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mSIZE\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mSIZE\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdtype\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"float32\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 33\u001b[1;33m     \u001b[0mtotal_cam\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mget_heatmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mprediction\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"conv2d_5\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprediction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     34\u001b[0m     \u001b[0mtotal_cam\u001b[0m \u001b[1;33m-=\u001b[0m \u001b[0mget_heatmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mprediction\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"conv2d_5\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprediction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m     \u001b[0mtotal_cam\u001b[0m \u001b[1;33m/=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mabs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtotal_cam\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-9-a3935247df30>\u001b[0m in \u001b[0;36mget_heatmap\u001b[1;34m(model, pred_img, last_layer, heatmap_for_index)\u001b[0m\n\u001b[0;32m     17\u001b[0m     \u001b[0mpooled_grads\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgrads\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m     \u001b[0miterate\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpooled_grads\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlast_conv_layer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m     \u001b[0mpooled_grads_value\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconv_layer_output_value\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0miterate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpooled_grads\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m         \u001b[0mconv_layer_output_value\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m*=\u001b[0m \u001b[0mpooled_grads_value\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\se7en\\anaconda3\\envs\\kaif\\lib\\site-packages\\tensorflow\\python\\keras\\backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   3630\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3631\u001b[0m     fetched = self._callable_fn(*array_vals,\n\u001b[1;32m-> 3632\u001b[1;33m                                 run_metadata=self.run_metadata)\n\u001b[0m\u001b[0;32m   3633\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3634\u001b[0m     output_structure = nest.pack_sequence_as(\n",
      "\u001b[1;32mc:\\users\\se7en\\anaconda3\\envs\\kaif\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1470\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[0;32m   1471\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1472\u001b[1;33m                                                run_metadata_ptr)\n\u001b[0m\u001b[0;32m   1473\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1474\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: You must feed a value for placeholder tensor 'conv2d_input_2' with dtype float and shape [?,180,180,3]\n\t [[{{node conv2d_input_2}}]]"
     ]
    }
   ],
   "source": [
    "image_size = 180\n",
    "img = image.load_img(img_file,target_size=(SIZE,SIZE))\n",
    "\n",
    "img_tensor = tf.keras.preprocessing.image.img_to_array(img)\n",
    "img_tensor = np.expand_dims(img_tensor, axis=0)\n",
    "# img_tensor = preprocess_input(img_tensor)\n",
    "\n",
    "heat_img = heatmap(img_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_4 (Conv2D)            (None, 178, 178, 32)      896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 89, 89, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 87, 87, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 43, 43, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 41, 41, 128)       73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 20, 20, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 18, 18, 128)       147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2 (None, 9, 9, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 10368)             0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 10368)             0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 512)               5308928   \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 513       \n",
      "=================================================================\n",
      "Total params: 5,550,273\n",
      "Trainable params: 5,550,273\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"strided_slice_11:0\", shape=(1,), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.applications.vgg16 import preprocess_input\n",
    "from tensorflow.keras.preprocessing.image import load_img\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "from tensorflow.keras import preprocessing\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras import models\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "image_size = 180\n",
    "\n",
    "# Load pre-trained Keras model and the image to classify\n",
    "# model = tf.keras.applications.vgg16.VGG16()\n",
    "image = np.random.random((image_size, image_size, 3))\n",
    "img_tensor = preprocessing.image.img_to_array(image)\n",
    "img_tensor = np.expand_dims(img_tensor, axis=0)\n",
    "img_tensor = preprocess_input(img_tensor)\n",
    "\n",
    "conv_layer = model.get_layer(\"conv2d_7\")\n",
    "heatmap_model = models.Model([model.inputs], [conv_layer.output, model.output])\n",
    "# Get gradient of the winner class w.r.t. the output of the (last) conv. layer\n",
    "with tf.GradientTape() as gtape:\n",
    "    conv_output, predictions = heatmap_model(img_tensor)\n",
    "    print(predictions[0])\n",
    "#     loss = predictions[:, np.argmax(predictions)]\n",
    "#     grads = gtape.gradient(loss, conv_output)\n",
    "#     pooled_grads = K.mean(grads, axis=(0, 1, 2))\n",
    "\n",
    "# heatmap = tf.reduce_mean(tf.multiply(pooled_grads, conv_output), axis=-1)\n",
    "# heatmap = np.maximum(heatmap, 0)\n",
    "# max_heat = np.max(heatmap)\n",
    "# if max_heat == 0:\n",
    "#     max_heat = 1e-10\n",
    "# heatmap /= max_heat\n",
    "\n",
    "# print(heatmap.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
    "\n",
    "local_weights_file = \"C:/Users/se7en/Desktop/dd/inception/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\"\n",
    "size = 80\n",
    "\n",
    "pre_trained_model = InceptionV3(input_shape = (size, size,3), \n",
    "                                include_top = False, \n",
    "                                weights = None)\n",
    "\n",
    "pre_trained_model.load_weights(local_weights_file)\n",
    "\n",
    "for layer in pre_trained_model.layers:\n",
    "  layer.trainable = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pre_trained_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "last layer output shape:  (None, 3, 3, 768)\n"
     ]
    }
   ],
   "source": [
    "last_layer = pre_trained_model.get_layer('mixed7')\n",
    "print('last layer output shape: ', last_layer.output_shape)\n",
    "last_output = last_layer.output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import RMSprop\n",
    "\n",
    "x = layers.GlobalAveragePooling2D()(last_output)\n",
    "# Flatten the output layer to 1 dimension\n",
    "x = layers.Flatten()(x)\n",
    "# Add a fully connected layer with 1,024 hidden units and ReLU activation\n",
    "x = layers.Dense(1024, activation='relu')(x)\n",
    "# Add a dropout rate of 0.2\n",
    "x = layers.Dropout(0.7)(x)                  \n",
    "# Add a final sigmoid layer for classification\n",
    "x = layers.Dense(1, activation='sigmoid')(x)           \n",
    "\n",
    "model = Model( pre_trained_model.input, x) \n",
    "\n",
    "model.compile(optimizer = RMSprop(lr=0.0001), \n",
    "              loss = 'binary_crossentropy', \n",
    "              metrics = ['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1908 images belonging to 2 classes.\n",
      "Found 335 images belonging to 2 classes.\n",
      "{'drowsiness': 0, 'undrowsiness': 1}\n",
      "{'drowsiness': 0, 'undrowsiness': 1}\n",
      "[0 0 0 ... 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "base_dir = 'img_data'\n",
    "\n",
    "# train_dir = os.path.join( base_dir, 'train')\n",
    "# validation_dir = os.path.join( base_dir, 'validation')\n",
    "\n",
    "\n",
    "# train_drowsiness_dir = os.path.join(train_dir, 'drowsiness') # Directory with our training drowsiness pictures\n",
    "# train_undrowsiness_dir = os.path.join(train_dir, 'undrowsiness') # Directory with our training undrowsiness pictures\n",
    "# validation_drowsiness_dir = os.path.join(validation_dir, 'drowsiness') # Directory with our validation drowsiness pictures\n",
    "# validation_undrowsiness_dir = os.path.join(validation_dir, 'undrowsiness')# Directory with our validation undrowsiness pictures\n",
    "\n",
    "# train_drowsiness_fnames = os.listdir(train_drowsiness_dir)\n",
    "# train_undrowsiness_fnames = os.listdir(train_undrowsiness_dir)\n",
    "\n",
    "# Add our data-augmentation parameters to ImageDataGenerator\n",
    "train_datagen = ImageDataGenerator(rescale = 1./255.,\n",
    "                                   rotation_range = 40,\n",
    "                                   width_shift_range = 0.2,\n",
    "                                   height_shift_range = 0.2,\n",
    "                                   brightness_range=None,\n",
    "                                   shear_range=0.2,\n",
    "                                   zoom_range=0.3,\n",
    "                                   channel_shift_range=0.0,\n",
    "                                   fill_mode=\"nearest\",\n",
    "                                   horizontal_flip = True,\n",
    "                                   validation_split=0.15,)\n",
    "\n",
    "# Note that the validation data should not be augmented!\n",
    "# test_datagen = ImageDataGenerator( rescale = 1.0/255. )\n",
    "\n",
    "# Flow training images in batches of 20 using train_datagen generator\n",
    "train_generator = train_datagen.flow_from_directory(base_dir,\n",
    "                                                    subset = 'training',\n",
    "                                                    shuffle=True,\n",
    "                                                    batch_size = 30,\n",
    "                                                    class_mode = 'binary', \n",
    "                                                    target_size = (size, size))     \n",
    "\n",
    "# Flow validation images in batches of 20 using test_datagen generator\n",
    "validation_generator =  train_datagen.flow_from_directory(base_dir,\n",
    "                                                          shuffle=True,\n",
    "                                                          subset = 'validation',\n",
    "                                                          batch_size  = 10,\n",
    "                                                          class_mode  = 'binary', \n",
    "                                                          target_size = (size, size))\n",
    "print(train_generator.class_indices)\n",
    "print(validation_generator.class_indices)\n",
    "print(train_generator.classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "64/64 [==============================] - 152s 2s/step - loss: 0.6567 - accuracy: 0.6132 - val_loss: 0.6264 - val_accuracy: 0.6388\n",
      "Epoch 2/5\n",
      "64/64 [==============================] - 102s 2s/step - loss: 0.5901 - accuracy: 0.6468 - val_loss: 0.6213 - val_accuracy: 0.6478\n",
      "Epoch 3/5\n",
      "64/64 [==============================] - 60s 933ms/step - loss: 0.5555 - accuracy: 0.6944 - val_loss: 0.5936 - val_accuracy: 0.6687\n",
      "Epoch 4/5\n",
      "64/64 [==============================] - 80s 1s/step - loss: 0.5326 - accuracy: 0.7301 - val_loss: 0.5716 - val_accuracy: 0.6955\n",
      "Epoch 5/5\n",
      "64/64 [==============================] - 100s 2s/step - loss: 0.4909 - accuracy: 0.7552 - val_loss: 0.5705 - val_accuracy: 0.6896\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "            train_generator,\n",
    "            validation_data = validation_generator,\n",
    "            epochs = 5,\n",
    "            verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(len(acc))\n",
    "\n",
    "plt.plot(epochs, acc, 'r', label='Training accuracy')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation accuracy')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.legend(loc=0)\n",
    "plt.figure()\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('model_13Nov_3epoch_tf_smooth.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidArgumentError",
     "evalue": "Expected image (JPEG, PNG, or GIF), got unknown format starting with 'test.jpg' [Op:DecodeJpeg]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31m_FallbackException\u001b[0m                        Traceback (most recent call last)",
      "\u001b[1;32mc:\\users\\se7en\\anaconda3\\envs\\kaif\\lib\\site-packages\\tensorflow\\python\\ops\\gen_image_ops.py\u001b[0m in \u001b[0;36mdecode_jpeg\u001b[1;34m(contents, channels, ratio, fancy_upscaling, try_recover_truncated, acceptable_fraction, dct_method, name)\u001b[0m\n\u001b[0;32m   1053\u001b[0m         \u001b[0mtry_recover_truncated\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"acceptable_fraction\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0macceptable_fraction\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1054\u001b[1;33m         \"dct_method\", dct_method)\n\u001b[0m\u001b[0;32m   1055\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31m_FallbackException\u001b[0m: This function does not handle the case of the path where all inputs are not already EagerTensors.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-eb4b04a871c3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;31m# image = cv2.imread(\"test.jpg\")\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[0mimage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecode_jpeg\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"test.jpg\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[0mimage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\se7en\\anaconda3\\envs\\kaif\\lib\\site-packages\\tensorflow\\python\\ops\\gen_image_ops.py\u001b[0m in \u001b[0;36mdecode_jpeg\u001b[1;34m(contents, channels, ratio, fancy_upscaling, try_recover_truncated, acceptable_fraction, dct_method, name)\u001b[0m\n\u001b[0;32m   1061\u001b[0m             \u001b[0mtry_recover_truncated\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtry_recover_truncated\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1062\u001b[0m             \u001b[0macceptable_fraction\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0macceptable_fraction\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdct_method\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdct_method\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1063\u001b[1;33m             name=name, ctx=_ctx)\n\u001b[0m\u001b[0;32m   1064\u001b[0m       \u001b[1;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_SymbolicException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1065\u001b[0m         \u001b[1;32mpass\u001b[0m  \u001b[1;31m# Add nodes to the TensorFlow graph.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\se7en\\anaconda3\\envs\\kaif\\lib\\site-packages\\tensorflow\\python\\ops\\gen_image_ops.py\u001b[0m in \u001b[0;36mdecode_jpeg_eager_fallback\u001b[1;34m(contents, channels, ratio, fancy_upscaling, try_recover_truncated, acceptable_fraction, dct_method, name, ctx)\u001b[0m\n\u001b[0;32m   1133\u001b[0m   \"acceptable_fraction\", acceptable_fraction, \"dct_method\", dct_method)\n\u001b[0;32m   1134\u001b[0m   _result = _execute.execute(b\"DecodeJpeg\", 1, inputs=_inputs_flat,\n\u001b[1;32m-> 1135\u001b[1;33m                              attrs=_attrs, ctx=ctx, name=name)\n\u001b[0m\u001b[0;32m   1136\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0m_execute\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmust_record_gradient\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1137\u001b[0m     _execute.record_gradient(\n",
      "\u001b[1;32mc:\\users\\se7en\\anaconda3\\envs\\kaif\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[1;32m---> 60\u001b[1;33m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: Expected image (JPEG, PNG, or GIF), got unknown format starting with 'test.jpg' [Op:DecodeJpeg]"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "face_cascade = cv2.CascadeClassifier(\"data/haarcascade_frontalface_alt.xml\")\n",
    "label = [\"dr\",\"udr\"]\n",
    "import numpy as np\n",
    "\n",
    "# image = cv2.imread(\"test.jpg\")\n",
    "\n",
    "# image = tf.image.decode_jpeg(\"test.jpg\")\n",
    "# image = tf.cast(image, tf.float32)\n",
    "plt.imshow(image)\n",
    "plt.show()\n",
    "img_array = img_to_array(image)\n",
    "img_array = np.array(img_array,dtype='uint8')\n",
    "# img = cv2.imshow('test.jpg')\n",
    "gray = cv2.cvtColor(img_array,cv2.COLOR_BGR2GRAY)\n",
    "gray = np.array(gray, dtype='uint8')\n",
    "# gray = cv2.fastNlMeansDenoisingColored(gray,None,10,10,7,21)\n",
    "faces = face_cascade.detectMultiScale(gray, scaleFactor = 1.1, minNeighbors = 5)\n",
    "for (x,y,w,h) in faces:\n",
    "#         print(x,y,w,h)\n",
    "    roi_image = img_array[y:y+h,x:x+w]\n",
    "\n",
    "    roi_image = cv2.resize(roi_image, (size,size))\n",
    "    roi_image = cv2.fastNlMeansDenoisingColored(roi_image,None,10,10,7,21)\n",
    "#     roi_image = tf.cast(roi_image, tf.float32)\n",
    "    roi_image = np.array(roi_image,dtype='uint8')\n",
    "#     roi_image = roi_image.astype('float32')\n",
    "    p = model.predict([roi_image.reshape((1,size,size,3))])\n",
    "    print(p)\n",
    "\n",
    "\n",
    "# def makeimage(path):\n",
    "#     frame = load_img(path,target_size = (size,size))\n",
    "#     frame = img_to_array(frame)\n",
    "#     return np.array([frame])\n",
    "\n",
    "\n",
    "# def prepare(path):\n",
    "#     size = 150\n",
    "#     img_array = cv2.imread(path)\n",
    "#     gray = cv2.cvtColor(img_array, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "#     faces = face_cascade.detectMultiScale(gray, scaleFactor = 1.2, minNeighbors = 7)\n",
    "#     for (x,y,w,h) in faces:\n",
    "# #         print(x,y,w,h)\n",
    "#         roi_image = img_array[y:y+h,x:x+w]\n",
    "        \n",
    "#         roi_image = cv2.resize(roi_image, (size,size))\n",
    "#         roi_image = cv2.fastNlMeansDenoisingColored(roi_image,None,10,10,7,21)\n",
    "#         roi_image = np.array([roi_image],'float64')\n",
    "# #         plt.imshow(roi_image,cmap='binary')\n",
    "# #         plt.show()\n",
    "# #         print(roi_image.shape)\n",
    "#         return roi_image.reshape((1,150,150,3))\n",
    "#     img_array = cv2.resize(img_array , (size,size))\n",
    "#     return img_array.reshape((1,150,150,3))\n",
    "# p = model.predict(prepare('test.jpg'))\n",
    "# print(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.4.0) C:\\Users\\appveyor\\AppData\\Local\\Temp\\1\\pip-req-build-2b5g8ysb\\opencv\\modules\\imgproc\\src\\color.cpp:182: error: (-215:Assertion failed) !_src.empty() in function 'cv::cvtColor'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-16-aa5caddc09f7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     18\u001b[0m     \u001b[1;31m# Our operations on the frame come here\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;31m#     frame = cv2.fastNlMeansDenoisingColored(frame,None,10,10,7,21)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m     \u001b[0mgray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCOLOR_BGR2GRAY\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     21\u001b[0m     \u001b[0mfaces\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mface_cascade\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdetectMultiScale\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscaleFactor\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1.1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mminNeighbors\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mh\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mfaces\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.4.0) C:\\Users\\appveyor\\AppData\\Local\\Temp\\1\\pip-req-build-2b5g8ysb\\opencv\\modules\\imgproc\\src\\color.cpp:182: error: (-215:Assertion failed) !_src.empty() in function 'cv::cvtColor'\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "cap = cv2.VideoCapture(0)\n",
    "label = \"Test\"\n",
    "count = 0\n",
    "size = 150\n",
    "labels = [\"drowsiness\" , \"undrowsiness\"]\n",
    "face_cascade = cv2.CascadeClassifier(\"data/haarcascade_frontalface_alt.xml\")\n",
    "while(True):\n",
    "    # Capture frame-by-frame\n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "#     rgb_img = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "#     rgb_img = cv2.resize(rgb_img,(size,size))\n",
    "#     rgb_img = rgb_img.reshape((1,size,size,3))\n",
    "#     class_index = model.predict([rgb_img])[0][0]\n",
    "#     label = labels[int(class_index)]\n",
    "\n",
    "    # Our operations on the frame come here\n",
    "#     frame = cv2.fastNlMeansDenoisingColored(frame,None,10,10,7,21)\n",
    "    \n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    faces = face_cascade.detectMultiScale(gray, scaleFactor = 1.1, minNeighbors = 5)\n",
    "    for (x,y,w,h) in faces:\n",
    "#         print(x,y,w,h)\n",
    "        roi_image = frame[y:y+h,x:x+w]\n",
    "        \n",
    "        roi_image = cv2.resize(roi_image , (size , size))\n",
    "        pre = model.predict([roi_image.reshape((1,150,150,3))])\n",
    "        color = (0,45,255)\n",
    "        stroke = 2\n",
    "        end_x = x+w\n",
    "        end_y = y+h\n",
    "        cv2.rectangle(frame, (x,y), (end_x,end_y), color, stroke)\n",
    "        label = labels[int(pre[0][0])]\n",
    "        print(label,pre)\n",
    "\n",
    "    cv2.putText(frame,label, (5,450), cv2.FONT_HERSHEY_SIMPLEX, 2, (250,255,255))\n",
    "    cv2.imshow('frame',frame)\n",
    "    count+=1\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# When everything done, release the capture\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not broadcast input array from shape (74,74) into shape (10,10)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-18-2f6d1d56c59a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     63\u001b[0m       \u001b[0mx\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m128\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     64\u001b[0m       \u001b[0mx\u001b[0m  \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m255\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'uint8'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 65\u001b[1;33m       \u001b[0mdisplay_grid\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0msize\u001b[0m \u001b[1;33m:\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0msize\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m \u001b[1;31m# Tile each filter into a horizontal grid\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     66\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     67\u001b[0m     \u001b[1;31m#-----------------\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: could not broadcast input array from shape (74,74) into shape (10,10)"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The history saving thread hit an unexpected error (OperationalError('database is locked')).History will not be written to the database.\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "import numpy as np\n",
    "import random\n",
    "import tensorflow as tf\n",
    "from   tensorflow.keras.preprocessing.image import img_to_array, load_img\n",
    "\n",
    "d_dir = \"img_data/drowsiness\"\n",
    "ud_dir = \"img_data/undrowsiness\"\n",
    "d_img = os.listdir(d_dir)\n",
    "ud_img = os.listdir(ud_dir)\n",
    "# Let's define a new Model that will take an image as input, and will output\n",
    "# intermediate representations for all layers in the previous model after\n",
    "# the first.\n",
    "successive_outputs = [layer.output for layer in model.layers[1:]]\n",
    "\n",
    "#visualization_model = Model(img_input, successive_outputs)\n",
    "visualization_model = tf.keras.models.Model(inputs = model.input, outputs = successive_outputs)\n",
    "\n",
    "# Let's prepare a random input image of a cat or dog from the training set.\n",
    "d_img_files = [os.path.join(d_dir, f) for f in d_img]\n",
    "ud_img_files = [os.path.join(ud_dir, f) for f in ud_img]\n",
    "\n",
    "img_path = random.choice(d_img_files + ud_img_files)\n",
    "img = load_img(img_path, target_size=(150, 150))  # this is a PIL image\n",
    "\n",
    "x   = img_to_array(img)                           # Numpy array with shape (150, 150, 3)\n",
    "x   = x.reshape((1,) + x.shape)                   # Numpy array with shape (1, 150, 150, 3)\n",
    "\n",
    "# Rescale by 1/255\n",
    "x /= 255.0\n",
    "\n",
    "# Let's run our image through our network, thus obtaining all\n",
    "# intermediate representations for this image.\n",
    "successive_feature_maps = visualization_model.predict(x)\n",
    "\n",
    "# These are the names of the layers, so can have them as part of our plot\n",
    "layer_names = [layer.name for layer in model.layers]\n",
    "\n",
    "# -----------------------------------------------------------------------\n",
    "# Now let's display our representations\n",
    "# -----------------------------------------------------------------------\n",
    "for layer_name, feature_map in zip(layer_names, successive_feature_maps):\n",
    "  \n",
    "  if len(feature_map.shape) == 4:\n",
    "    \n",
    "    #-------------------------------------------\n",
    "    # Just do this for the conv / maxpool layers, not the fully-connected layers\n",
    "    #-------------------------------------------\n",
    "    n_features = feature_map.shape[-1]  # number of features in the feature map\n",
    "    size       = feature_map.shape[ 1]  # feature map shape (1, size, size, n_features)\n",
    "    \n",
    "    # We will tile our images in this matrix\n",
    "    display_grid = np.zeros((size, size * n_features))\n",
    "    \n",
    "    #-------------------------------------------------\n",
    "    # Postprocess the feature to be visually palatable\n",
    "    #-------------------------------------------------\n",
    "    for i in range(n_features):\n",
    "      x  = feature_map[0, :, :, i]\n",
    "      x -= x.mean()\n",
    "      x /= x.std ()\n",
    "      x *=  64\n",
    "      x += 128\n",
    "      x  = np.clip(x, 0, 255).astype('uint8')\n",
    "      display_grid[:, i * size : (i + 1) * size] = x # Tile each filter into a horizontal grid\n",
    "\n",
    "    #-----------------\n",
    "    # Display the grid\n",
    "    #-----------------\n",
    "\n",
    "    scale = 20. / n_features\n",
    "    plt.figure( figsize=(scale * n_features, scale) )\n",
    "    plt.title ( layer_name )\n",
    "    plt.grid  ( False )\n",
    "    plt.imshow( display_grid, aspect='auto', cmap='viridis' ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
